{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "def position_encoding(\n",
    "    seq_len: int,\n",
    "    dim_model: int,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    ") -> Tensor:\n",
    "    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n",
    "    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n",
    "    phase = pos / (1e4 ** torch.div(dim, dim_model, rounding_mode=\"floor\"))\n",
    "\n",
    "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))\n",
    "\n",
    "\n",
    "def feed_forward(dim_input: int = 512, dim_feedforward: int = 2048) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim_input, dim_feedforward),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(dim_feedforward, dim_input),\n",
    "    )\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors: Tensor) -> Tensor:\n",
    "        # Assume that the \"query\" tensor is given first, so we can compute the\n",
    "        # residual.  This matches the signature of 'MultiHeadAttention'.\n",
    "        return self.norm(tensors[0] + self.dropout(self.sublayer(*tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "    temp = query.bmm(key.transpose(1, 2))\n",
    "    scale = query.size(-1) ** 0.5\n",
    "    softmax = f.softmax(temp / scale, dim=-1)\n",
    "    return softmax.bmm(value)\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(dim_in, dim_q)\n",
    "        self.k = nn.Linear(dim_in, dim_k)\n",
    "        self.v = nn.Linear(dim_in, dim_k)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return scaled_dot_product_attention(self.q(query), self.k(key), self.v(value))\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(dim_in, dim_q, dim_k) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * dim_k, dim_in)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return self.linear(\n",
    "            torch.cat([h(query, key, value) for h in self.heads], dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 6,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "        self.attention = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        src = self.attention(src, src, src)\n",
    "        return self.feed_forward(src)\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 6,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        seq_len, dimension = src.size(1), src.size(2)\n",
    "        src += position_encoding(seq_len, dimension)\n",
    "        for layer in self.layers:\n",
    "            src = layer(src)\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 6,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "        self.attention_1 = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.attention_2 = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "        tgt = self.attention_1(tgt, tgt, tgt)\n",
    "        tgt = self.attention_2(tgt, memory, memory)\n",
    "        return self.feed_forward(tgt)\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 6,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerDecoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.linear = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "        seq_len, dimension = tgt.size(1), tgt.size(2)\n",
    "        tgt += position_encoding(seq_len, dimension)\n",
    "        for layer in self.layers:\n",
    "            tgt = layer(tgt, memory)\n",
    "\n",
    "        return torch.softmax(self.linear(tgt), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers: int = 6,\n",
    "        num_decoder_layers: int = 6,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 6,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(\n",
    "            num_layers=num_encoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(\n",
    "            num_layers=num_decoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor) -> Tensor:\n",
    "        return self.decoder(tgt, self.encoder(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "src = torch.rand(64, 1, 512)\n",
    "tgt = torch.rand(64, 1, 512)\n",
    "out = Transformer()(src, tgt)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c38c8779811d1cfaf4b5a784c97578f212c26cffc36ab1ef679f872ba1fdba43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
